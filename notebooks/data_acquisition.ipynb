{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_classifier(path,service,sheet):\n",
    "    \n",
    "    df_list =[]\n",
    "    \n",
    "    for root, dirs, files in os.walk(path):\n",
    "        \n",
    "        for filename in files:\n",
    "            \n",
    "            if filename.startswith(service):\n",
    "                \n",
    "                df_list.append(pd.read_excel(f'{path}{filename}', sheet_name=sheet))\n",
    "            \n",
    "                print(filename)\n",
    "                \n",
    "            elif service == 'all':\n",
    "                \n",
    "                df_list.append(pd.read_excel(f'{path}{filename}', sheet_name=sheet))\n",
    "                \n",
    "                print(filename)\n",
    "                \n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hl1986to2001.xlsx\n",
      "gtgg1986to2001.xlsx\n",
      "hl2010toPresent.xlsx\n",
      "hl2002to2009.xlsx\n",
      "lng2011toPresent.xlsx\n",
      "gd2010toPresent.xlsx\n",
      "gtgg2002to2009.xlsx\n",
      "gtggungs2010toPresent.xlsx\n",
      "gdmar2004to2009.xlsx\n",
      "gd1986tofeb2004.xlsx\n"
     ]
    }
   ],
   "source": [
    "df_list = df_classifier(path, 'all', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Drop columns with high nan percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_removal(df):\n",
    "\n",
    "    nan_values = df.isna().sum()\n",
    "        \n",
    "    nan_percentage = nan_values / len(df) * 100\n",
    "        \n",
    "    filter_nan_percentage = nan_percentage > 20\n",
    "    \n",
    "    high_nan_columns = df.columns[filter_nan_percentage].to_list()\n",
    "    \n",
    "    return df.drop(columns=high_nan_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fill nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_col_selection(df):\n",
    "    \n",
    "    return df.columns[df.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_num_col(df, column_list):\n",
    "    \n",
    "    return df[column_list].select_dtypes(include=['float64', 'int64']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_cat_col(df, column_list):\n",
    "    \n",
    "    return df[column_list].select_dtypes(exclude=['float64', 'int64']).fillna('NO DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_clean(df, df_cat, df_num):\n",
    "    \n",
    "    for column in df_cat.columns:\n",
    "    \n",
    "        df[column] = df_cat[column]\n",
    "    \n",
    "    for column in df_num.columns:\n",
    "    \n",
    "        df[column] = df_num[column]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_list:\n",
    "    \n",
    "    df.drop(columns='DATAFILE_AS_OF', inplace=True)\n",
    "    \n",
    "    nan_removal(df)\n",
    "    \n",
    "    df_clean(df, fillna_cat_col(df, nan_col_selection(df)), fillna_num_col(df, nan_col_selection(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Renaming of variables to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_list:\n",
    "    \n",
    "    df.rename(columns={'ACCTY' : 'LOCATION_CITY_NAME',\n",
    "                      'ACCNT' : 'LOCATION_COUNTY_NAME',\n",
    "                       'ACCOUNTY' : 'LOCATION_COUNTY_NAME',\n",
    "                       'ACCST' : 'LOCATION_STATE_ABBREVIATION',\n",
    "                       'ACSTATE' : 'LOCATION_STATE_ABBREVIATION',\n",
    "                       'ACZIP' : 'LOCATION_POSTAL_CODE',\n",
    "                       'RPTID' : 'REPORT_NUMBER',\n",
    "                       'INADR' : 'LOCATION_STREET_ADDRESS',\n",
    "                       'CLASS' : 'CLASS_LOCATION_TYPE',\n",
    "                       'COMM' : 'COMMODITY_RELEASED_TYPE',\n",
    "                       'CSYS' : 'SYSTEM_PART_INVOLVED',\n",
    "                       'OFFSHORE' : 'ON_OFF_SHORE',\n",
    "                      'OPID' : 'OPERATOR_ID',\n",
    "                      'IFED' : 'FEDERAL',\n",
    "                       'IDATE' : 'LOCAL_DATETIME',\n",
    "                       'INTER' : 'PIPE_FACILITY_TYPE',\n",
    "                       'TFAT' : 'FATAL',\n",
    "                       'EFAT' : 'NUM_EMP_FATALITIES',\n",
    "                       'FAT' : 'FATAL',\n",
    "                       'TINJ' : 'INJURE',\n",
    "                       'EINJ' : 'NUM_EMP_INJURIES',\n",
    "                       'INJ' : 'INJURE',\n",
    "                       'ACPRS' : 'ACCIDENT_PSIG',\n",
    "                       'INPRS' : 'ACCIDENT_PSIG',\n",
    "                       'MXPRS' : 'MOP_PSIG',\n",
    "                       'DSPRS' : 'MOP_PSIG',\n",
    "                       'PRTST' : 'MOP_CFR_SECTION',\n",
    "                       'TEST' : 'EX_HYDROTEST_PRESSURE',\n",
    "                       'PRTLK' : 'CUSTOMER_TYPE',\n",
    "                       'MLKD' : 'MATERIAL_INVOLVED',\n",
    "                       'NMDIA' : 'PIPE_DIAMETER',\n",
    "                       'THK' : 'WT_STEEL',\n",
    "                       'SPEC' : 'PIPE_SPECIFICATION',\n",
    "                       'PRTYR' : 'INSTALLATION_YEAR',\n",
    "                       'ITMYR' : 'INSTALLATION_YEAR',\n",
    "                       'MANYR' : 'MANUFACTURED_YEAR',\n",
    "                       'MANU' : 'PIPE_MANUFACTURER',\n",
    "                       'LOCLK' : 'INCIDENT_AREA_SUBTYPE',\n",
    "                       'PNAME' : 'PREPARER_NAME',\n",
    "                       'PHONE' : 'PREPARER_PHONE',\n",
    "                       'PROT' : 'UNDER_CATHODIC_PROTECTION_IND',\n",
    "                       'FACAT' : 'UNDER_CATHODIC_PROTECTION_IND',\n",
    "                       'CAULK' : 'CAUSE_DETAILS',\n",
    "                       'ORGLK' : 'ITEM_INVOLVED',\n",
    "                       'PRTFL' : 'SYSTEM_PART_DETAILS',\n",
    "                       'LOSS' : 'UNINTENTIONAL_RELEASE_BBLS',\n",
    "                       'RECOV' : 'RECOVERED_BBLS',\n",
    "                       'FIRE' : 'IGNITE_IND',\n",
    "                       'EXP' : 'EXPLODE_IND',\n",
    "                       'SMYS' : 'PIPE_SMYS',\n",
    "                       'CORRO' : 'CORROSION_TYPE',\n",
    "                       'CORLC' : 'EXT_INT_CORROSION'\n",
    "                      }, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - hl_1986_to_2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[0].drop(columns = ['COOR', 'SPLOC', 'TELRN', 'ORGLO',\n",
    "                          'CAUSO', 'NFAT', 'NINJ', 'CORR', 'PREVT',\n",
    "                          'JNT', 'MOP_PSIG', 'DUR', 'CAULO', 'TMPMK',\n",
    "                          'FACTD', 'ONECL', 'ONEOT', 'EXCAL'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[0].PIPE_FACILITY_TYPE.replace(['YES', 'NO'],['INTERSTATE', 'INTRASTATE'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[0].OFFSHORE.replace(['YES', 'NO'],['OFFSHORE', 'ONSHORE'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - gtgg_1986_to_2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SIGNIFICANT', 'SERIOUS', 'SYSTEM_TYPE', 'REPORT_NUMBER', 'OPERATOR_ID',\n",
       "       'NAME', 'LOCATION_CITY_NAME', 'LOCATION_COUNTY_NAME',\n",
       "       'LOCATION_STATE_ABBREVIATION', 'LOCATION_POSTAL_CODE', 'MPOST', 'SURVY',\n",
       "       'DTHH', 'LOCAL_DATETIME', 'CLASS_LOCATION_TYPE', 'SHORE', 'OFFAREA',\n",
       "       'BNUMB', 'OFFST', 'OCS', 'FEDERAL', 'ITYPE', 'FATAL', 'INJURE',\n",
       "       'TOTAL_COST', 'TOTAL_COST_IN84', 'TOTAL_COST_CURRENT', 'OPJUD', 'STHH',\n",
       "       'STMN', 'TELRN', 'TELRT', 'ACCIDENT_PSIG', 'MOP_PSIG', 'MPEST',\n",
       "       'EX_HYDROTEST_PRESSURE', 'CAUSE', 'MAP_CAUSE', 'MAP_SUBCAUSE',\n",
       "       'CUSTOMER_TYPE', 'SYSTEM_PART_DETAILS', 'PRTFO', 'MATERIAL_INVOLVED',\n",
       "       'MLKDO', 'PRTSY', 'PRTSO', 'INSTALLATION_YEAR', 'PIPE_DIAMETER',\n",
       "       'WT_STEEL', 'PIPE_SPECIFICATION', 'PIPE_SMYS', 'SEAM',\n",
       "       'PIPE_MANUFACTURER', 'MANUFACTURED_YEAR', 'INCIDENT_AREA_SUBTYPE',\n",
       "       'LOCLO', 'PREPARER_NAME', 'PREPARER_PHONE', 'DESCO', 'CAUCO',\n",
       "       'UNDER_CATHODIC_PROTECTION_IND', 'CAUSE_DETAILS', 'DMGO', 'NOTIF',\n",
       "       'MARK', 'MRKTP', 'STAT', 'CAULO', 'CTEST', 'MEDO', 'NARRATIVE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[1].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - gd_1986_to_2004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[9].drop(columns = ['OPJUD', 'STHH', 'STMN', 'TELRN', 'TELRT' ,\n",
    "                           'MPEST', 'NOTIF', 'MARK', 'STAT'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fixing Datetime Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl = df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time(df_column):\n",
    "    \n",
    "    time = datetime.strptime('{:04d}'.format(int(df_column)), '%H%M').time()\n",
    "    \n",
    "    strg = '{0:%H:%M}'.format(time)\n",
    "    \n",
    "    return strg[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'16:00'"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time(1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl.DTHH = hl.DTHH.astype('int64')\n",
    "\n",
    "type(hl['DTHH'].loc[1])\n",
    "\n",
    "#hl['hour'] = hl.apply(lambda x: time(x['DTHH']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18693, 270)"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedStuff = pd.concat(df_list , ignore_index=True)\n",
    "mergedStuff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ironhack_env]",
   "language": "python",
   "name": "conda-env-ironhack_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
